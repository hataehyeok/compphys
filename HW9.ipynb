{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO8kNtTbyk4K"
      },
      "source": [
        "# Problem 1 (Practice)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_tCMo2oynCC"
      },
      "source": [
        "We learned how to construct an AND operator in the lecture. We will repeat this exercise, this time constructing an OR operator.\n",
        "\n",
        "(a) Taking the two inputs as $x_1$ and $x_2$, predict what the values of the fitting parameters $W_1, W_2,$ and $b$ should be, where $v = W_1x_1 + W_2x_2 + b$. (10 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJa0aLWU65dv"
      },
      "source": [
        "(b) Write a program that learns to make the OR operator using perceptrons. Use $Nep=1000$ epochs, and a learning rate of $c=0.5$, and the sigmoid activation function\n",
        "\\begin{align*}\n",
        "  y=h(v)=\\frac{1}{1+e^{-v}}.\n",
        "\\end{align*}\n",
        "Use the gradient descent method as the learning algorithm. Use the initial guesses $W_1 = 1, W_2=0.1, b=-1$. For every epochs, save the squared error, $\\mathbf{W}$, and $b$. Plot the squared error as a function of epoch. Print out the initial and final $\\mathbf{W}$ vector and bias $b$. Do the final values match your predictions? [Hint: Normalize $\\mathbf{W}$ and $b$ by $W_1$ at when printing them.] (40 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxrSY2af8Hz7"
      },
      "source": [
        "(c) Generate 1000 random $(x_1,x_2)$ points from (0,0) to (1,1). Make a scatter plot of these points, with the colors representing the value of $h(v)$. Are the points well-classified? (15 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S_SzqJn-gN8"
      },
      "source": [
        "(d) Make a plot of the separator line $v=0$ as a function of epochs. (15 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD4FDx0VFECQ"
      },
      "source": [
        "(e) The bias $b$ can actually by written as $W_0$, and then $v=\\sum_{n=0}^2 W_n x_n$ where $x_0=1$. Modify your code so that instead of $b$, you provide a training data set including $x_0=1$ and learn the weight vector with three elements. Print out the final weight vector. Do the values agree with your previous result? (20 pts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
